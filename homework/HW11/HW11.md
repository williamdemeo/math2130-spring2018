## HW 11 

**DUE Friday, April 27, 9am**

### List of Exercises

**Section 5.4:** 2, 12, (21), (25), 26, (27)  
**Section 6.1:** 6, 10, 14, 16, 20, (27), 28, (30)    
**Section 6.2:** 10, 12, (13), 16, 24, (33)   

---

### Section 5.4
#### Exercises: 2, 12, (21), (25), 26, (27)  

**5.4.2.**
Let $\mathcal{D} = \{\mathbf{d}_1, \mathbf{d}_2\}$ 
and $\mathcal{B} = \{\mathbf{b}_1, \mathbf{b}_2\}$ 
be bases for vector spaces $V$ and $W$, respectively. 
Let $T :  V \to W$ be a linear transformation satisfying
\[
T (\mathbf{d}_1) = 2\mathbf{b}_1 - 3\mathbf{b}_2 \quad \text{ and } \quad
T (\mathbf{d}_2) = -4\mathbf{b}_1 + 5\mathbf{b}_2.
\]
Find the matrix for $T$ relative to $\mathcal{D}$ and $\mathcal{B}$.

---

**5.4.12.**
Find the $\mathcal{B}$-matrix for the transformation
$\mathbf{x} \mapsto A \mathbf{x}$, when 
$\mathcal{B} = \{\mathbf{b}_1, \mathbf{b}_2\}$, where 
\[A = \left[\begin{array}{r}
-1 & 4\\-2& 3 \end{array}\right],
\quad \mathbf{b}_1 = \left[\begin{array}{r}
3\\2 \end{array}\right], \quad
\mathbf{b}_2 =  â€ƒ\left[\begin{array}{r}
-1 \\ 1\end{array}\right].
\]

---

5.4.21. (recommended)   
Prove the following statement for square matrices, $A$, $B$, $C$.  If $B$ is similar to $A$ and $C$ is similar to $A$, then $B$ is similar
to $C$.

---

5.4.25. (recommended)  
The *trace* of a square matrix $A$ is the sum of the diagonal
entries in $A$ and is denoted by $\operatorname{tr} A$. 
It can be verified that $\operatorname{tr} (F G) = \operatorname{tr}(G F)$
for any two $n\times n$ matrices $F$ and $G$.
Show that if $A$ and $B$ are similar, then 
$\operatorname{tr} A = \operatorname{tr} B$.

---

**5.4.26.** It can be shown that the *trace* (see Exercise 5.4.25 for definition) 
of a matrix $A$ equals the sum of the eigenvalues of $A$. Verify this statement for the case when $A$ is diagonalizable.

---

5.4.27. (recommended)  
Let $V$ be $\mathbb{R}^n$ with a basis $\mathcal{B} = \{\mathbf{b}_1, \dots, \mathbf{b}_n\}$, let 
$W$ be $\mathbb{R}^n$ with a the standard basis, denoted $\mathcal{E}$.
Consider the identity transformation $I : V \to W$, where $I(\mathbf{x}) = \mathbf{x}$.
Find the matrix for $I$ relative to $\mathcal{B}$ and $\mathcal{E}$. 
What was this matrix called in Section 4.4?

---

### Section 6.1
#### Exercises: 6, 10, 14, 16, 20, (27), 28, (30)

**6.1.6.** Let
$\mathbf{w} = \left[\begin{array}{r}
3\\-1\\-5\end{array}\right]$
and $\mathbf{x} = \left[\begin{array}{r}
6\\-2\\3\end{array}\right]$. Compute
${\large \left(\frac{\mathbf{x} \cdot \mathbf{w}}{\mathbf{x}\cdot \mathbf{x}}\right)}$ $\mathbf{x}$

---

**6.1.10.**
Find a unit vector in the direction of the vector 
$\left[\begin{array}{r}
-6\\4\\-3\end{array}\right]$

---

**6.1.14.**
Find the distance between
$\mathbf{u} = \left[\begin{array}{r}
0\\-5\\2\end{array}\right]$
and 
$\mathbf{z} = \left[\begin{array}{r}
-4\\-1\\8\end{array}\right]$

---

**6.1.16.** Determine whether
$\mathbf{u} = \left[\begin{array}{r}12\\3\\-5\end{array}\right]$
and 
$\mathbf{v} = \left[\begin{array}{r} 2 \\ -3 \\ 3\end{array}\right]$
are orthogonal vectors.

---

**6.1.20.** Mark each statement True or False. Justify each answer.
All vectors are assumed to be in $\mathbb{R}^n$. 

**a.** $\mathbf{u} \cdot \mathbf{v} - \mathbf{v}\cdot \mathbf{u} = 0$

**b.** For any scalar $c$, $\|c\mathbf{v}\|= c\|\mathbf{v}\|$.

**c.** If $\mathbf{x}$ is orthogonal to every vector in a subspace $W$, 
then $\mathbf{x}$ is in $W^{\bot}$.

**d.** If 
$\|\mathbf{u}\|^2 + \|\mathbf{v}\|^2  = \|\mathbf{u} + \mathbf{v}\|^2$, 
then $\mathbf{u}$ and $\mathbf{v}$ are orthogonal.

**e.** For an $m \times n$ matrix $A$, vectors in the null space of $A$ are
orthogonal to vectors in the row space of $A$.

---

6.1.27. (recommended)  
Suppose a vector $\mathbf{y}$ is orthogonal to vectors $\mathbf{u}$ and 
$\mathbf{v}$. Show that $\mathbf{y}$ is orthogonal to the vector $\mathbf{u} + \mathbf{v}$.

---

**6.1.28.** Suppose $\mathbf{y}$ is orthogonal to 
$\mathbf{u}$ and 
$\mathbf{v}$. Show that 
$\mathbf{y}$ is orthogonal
to every $\mathbf{w}$ in 
$\operatorname{Span}\{\mathbf{u}, \mathbf{v}\}$. 
[*Hint:* An arbitrary $\mathbf{w}$ in 
$\operatorname{Span}\{\mathbf{u}, \mathbf{v}\}$ has the form 
$\mathbf{w} =  c_1 \mathbf{u} + c_2\mathbf{v}$;
show that $\mathbf{y}$ is orthogonal to
every such a vector.]

---

6.1.30. (recommended)   
Let $W$ be a subspace of $\mathbb{R}^n$, and let $W^{\bot}$ 
be the set of all vectors orthogonal to $W$. 
Show that $W^{\bot}$ is a subspace of $\mathbb{R}^n$
using the following steps.

**a.** Take $\mathbf{z}$ in $W^{\bot}$, and let $\mathbf{u}$ represent any element of $W$. Then $\mathbf{z} \cdot \mathbf{u} = 0$. 
Take any scalar $c$ and show that $c \mathbf{z}$ is orthogonal
to $\mathbf{u}$. (Since $\mathbf{u}$ was an arbitrary element of $W$, this will
show that $c\mathbf{z}$ is in $W^{\bot}$.)

**b.** Take $\mathbf{z}_1$ and $\mathbf{z}_2$ in $W^{\bot}$, and let 
$\mathbf{u}$ be any element of
$W$. Show that $\mathbf{z}_1+\mathbf{z}_2$ is orthogonal to $\mathbf{u}$. 
What can you conclude about $\mathbf{z}_1 + \mathbf{z}_2$? Why?

**c.** Finish the proof that $W^{\bot}$ is a subspace of $\mathbb{R}^n$.

---

#### Section 6.2
**Exercises: 10, 12, (13), 16, 24, (33)**   

**6.2.10.** Let
$\mathbf{u}_1 = \left[\begin{array}{r}3\\-3\\0\end{array}\right]$,
$\mathbf{u}_2 = \left[\begin{array}{r}2\\2\\-1\end{array}\right]$,
$\mathbf{u}_3 = \left[\begin{array}{r}1\\1\\4\end{array}\right]$,
and $\mathbf{x} = \left[\begin{array}{r}5\\-3\\1\end{array}\right]$.
Show that $\{\mathbf{u}_1, \mathbf{u}_2, \mathbf{u}_3\}$
is an orthogonal basis for $\mathbb{R}^3$. Then express $\mathbf{x}$ as a linear
combination of the $\mathbf{u}$'s.

---

**6.2.12.** Compute the orthogonal projection of 
$\left[\begin{array}{r}1\\-1\end{array}\right]$ onto the line through
$\left[\begin{array}{r}-1\\3\end{array}\right]$.

---

6.2.13. (recommended)    
Let $\mathbf{y} = \left[\begin{array}{r}2\\3\end{array}\right]$
and $\mathbf{u} = \left[\begin{array}{r}4\\-7\end{array}\right]$.
Write $\mathbf{y}$ as the sum of two orthogonal vectors, one in 
$\operatorname{Span}\{\mathbf{u}\}$ and the other orthogonal to 
$\mathbf{u}$.

---

**6.2.16.** Let $\mathbf{y} = \left[\begin{array}{r}-3\\9\end{array}\right]$
and $\mathbf{u} = \left[\begin{array}{r}1\\2\end{array}\right]$.
Compute the distance from $\mathbf{y}$ to the line passing through
$\mathbf{u}$ and the origin.

---

**6.2.24.**  Mark each statement True or False. Justify each answer.
All vectors are assumed to belong to $\mathbb{R}^n$. 

**a.** Not every orthogonal set in $\mathbb{R}^n$ is linearly independent.

**b.** If a set $S = \{\mathbf{u}_1, \dots, \mathbf{u}_p\}$
has the property that $\mathbf{u}_i \cdot \mathbf{u}_j = 0$
whenever $i \neq j$, then $S$ is an orthonormal set.

**c.** If the columns of an $m \times n$ matrix $A$ are orthonormal, then
the linear mapping $\mathbf{x} \mapsto A \mathbf{x}$ preserves lengths.

**d.** The orthogonal projection of $\mathbf{y}$ onto $\mathbf{v}$ is the same as the orthogonal projection of $\mathbf{y}$ onto $c\mathbf{v}$ whenever $c \neq 0$.

**e.** An orthogonal matrix is invertible.

---

6.2.33. (recommended)     
Suppose $\mathbf{u}$ is a nonzero vector in $\mathbb{R}^n$, and let $L = \operatorname{Span} \{\mathbf{u}\}$. Show that the mapping
$\mathbf{x} \mapsto \operatorname{proj}_L \mathbf{x}$ is a linear transformation.
